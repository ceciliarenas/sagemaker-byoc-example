{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Your Own Algorithm Container\n",
    "\n",
    "This notebook demonstrates how to package a custom algorithm for Amazon SageMaker using a decision tree classifier for the Iris dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Required Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sagemaker-studio-image-build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Push Container\n",
    "\n",
    "First ensure you have the proper IAM role trust policy configured:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trust Policy for IAM Role\n",
    "\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"codebuild.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# Build and push container\n",
    "algorithm_name=custom-algorithm-sklearn\n",
    "\n",
    "cd container\n",
    "\n",
    "chmod +x decision_tree/train\n",
    "chmod +x decision_tree/serve\n",
    "\n",
    "fullname=\"${algorithm_name}:latest\"\n",
    "rolename=\"Sagemaker_build_role\"\n",
    "sm-docker build . --repository ${fullname} --role ${rolename} --bucket sagemaker-demo-bpartner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 prefix and imports\n",
    "prefix = \"DEMO-scikit-byo-iris\"\n",
    "\n",
    "import boto3\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SageMaker session\n",
    "import sagemaker as sage\n",
    "from time import gmtime, strftime\n",
    "\n",
    "sess = sage.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data location and image URI\n",
    "data_location = 's3://sagemaker-demo-bpartner/input'\n",
    "\n",
    "# Replace with your ECR image URI\n",
    "image = \"992382645889.dkr.ecr.eu-west-1.amazonaws.com/custom-algorithm-sklearn:latest\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Train Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {\n",
    " \"max_leaf_nodes\": 3,\n",
    " \"random_state\": 0,\n",
    " \"criterion\": \"gini\"\n",
    "}\n",
    "\n",
    "estimator = sage.estimator.Estimator(\n",
    "    image,\n",
    "    role,\n",
    "    1,\n",
    "    \"ml.c4.2xlarge\",\n",
    "    output_path=\"s3://{}/output\".format(sess.default_bucket()),\n",
    "    sagemaker_session=sess,\n",
    "    hyperparameters=param_dict,\n",
    "    train_use_spot_instances=True,\n",
    "    train_max_run=3600,\n",
    "    train_max_wait=7200 \n",
    ")\n",
    "\n",
    "estimator.fit(data_location, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Model and Create Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "predictor = estimator.deploy(1, \"ml.m4.xlarge\", serializer=CSVSerializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = pd.read_csv(\"testpayload.csv\", header=None)\n",
    "\n",
    "# Create test data\n",
    "import itertools\n",
    "a = [10 * i for i in range(2)]\n",
    "b = [i for i in range(5)]\n",
    "indices = [i + j for i, j in itertools.product(a, b)]\n",
    "test_data = shape.iloc[indices[:-1]]\n",
    "\n",
    "# Get predictions\n",
    "print(predictor.predict(test_data.values).decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Batch Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Define locations\n",
    "bucket = 'sagemaker-demo-bpartner'\n",
    "input_prefix = 'batch-input'\n",
    "output_prefix = 'batch-output'\n",
    "\n",
    "# Upload test data\n",
    "s3_client = boto3.client('s3')\n",
    "s3_client.upload_file(\n",
    "    'testpayload.csv', \n",
    "    bucket, \n",
    "    f'{input_prefix}/testpayload.csv'\n",
    ")\n",
    "\n",
    "input_location = f's3://{bucket}/{input_prefix}'\n",
    "output_location = f's3://{bucket}/{output_prefix}'\n",
    "\n",
    "# Create transformer\n",
    "transformer = estimator.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    output_path=output_location,\n",
    "    strategy='SingleRecord'\n",
    ")\n",
    "\n",
    "# Start transform job\n",
    "transformer.transform(\n",
    "    input_location,\n",
    "    content_type='text/csv',\n",
    "    split_type='Line'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.delete_endpoint(predictor.endpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
